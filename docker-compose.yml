
services:
  mongodb:
    image: mongo:7.0
    container_name: mongodb
    environment:
      - MONGO_INITDB_ROOT_USERNAME=admin
      - MONGO_INITDB_ROOT_PASSWORD=admin123
      - MONGO_INITDB_DATABASE=messages_db
    volumes:
      - mongodb_data:/data/db
      - ./mongo-init.js:/docker-entrypoint-initdb.d/mongo-init.js:ro
    ports:
      - "27017:27017"
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s
    networks:
      - app_network
    restart: unless-stopped

  postgres:
    image: postgres:15
    container_name: postgres_db
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=messages
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-db.sh:/docker-entrypoint-initdb.d/init-db.sh
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow", "-d", "messages"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s
    networks:
      - app_network
    restart: unless-stopped

  airflow-init:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow_init
    depends_on:
      postgres:
        condition: service_healthy
      mongodb:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__PARALLELISM=8
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/messages
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY}
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=true
      - PYTHONPATH=/opt/airflow/src
      - DATABASE_URL=postgresql://airflow:airflow@postgres:5432/messages
      - MONGODB_URI=mongodb://admin:admin123@mongodb:27017/messages_db?authSource=admin
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - AIRFLOW_VAR_MONGODB_URI=mongodb://admin:admin123@mongodb:27017/messages_db?authSource=admin
      - WORKSPACE_PATH=/opt/airflow/src
      - FILTER_LINKS=${FILTER_LINKS:-true}
      - REQUIRED_DIGITS=${REQUIRED_DIGITS:-19}
      - EXCLUDE_TERMS=${EXCLUDE_TERMS:-}
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
      - /opt/airflow/src/node_modules
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./data:/data
      - ./.env:/opt/airflow/.env
      - ./extracted-links:/opt/airflow/extracted-links
      - ./filtered-links:/opt/airflow/filtered-links
      - ./workflows:/opt/airflow/workflows
      - ./automa:/opt/automa
    command: >
      bash -c "
        airflow db init &&
        airflow db upgrade &&
        airflow users create --username brian --firstname Brian --lastname Kimutai --role Admin --email briankimu97@gmail.com --password kimu
      "
    networks:
      - app_network
    restart: "no"

  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow_webserver
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
      mongodb:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__PARALLELISM=8
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/messages
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY}
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=true
      - PYTHONPATH=/opt/airflow/src
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - AIRFLOW_VAR_MONGODB_URI=mongodb://admin:admin123@mongodb:27017/messages_db?authSource=admin
      - WORKSPACE_PATH=/opt/airflow/src
      - FILTER_LINKS=${FILTER_LINKS:-true}
      - MONGODB_URI=mongodb://admin:admin123@mongodb:27017/messages_db?authSource=admin
      - DATABASE_URL=postgresql://airflow:airflow@postgres:5432/messages
      - REQUIRED_DIGITS=${REQUIRED_DIGITS:-19}
      - EXCLUDE_TERMS=${EXCLUDE_TERMS:-}
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
      - /opt/airflow/src/node_modules
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./data:/data
      - ./.env:/opt/airflow/.env
      - ./extracted-links:/opt/airflow/extracted-links
      - ./filtered-links:/opt/airflow/filtered-links
      - ./workflows:/opt/airflow/workflows
      - ./automa:/opt/automa
    ports:
      - "8080:8080"
    command: >
      bash -c "
        echo 'Waiting for database to be ready...';
        until airflow db check; do
          echo 'Database not ready yet. Retrying in 5 seconds...';
          sleep 5;
        done;
        echo 'Database connection successful!';
        airflow webserver
      "
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - app_network
    restart: unless-stopped

  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow_scheduler
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
      mongodb:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__PARALLELISM=8
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/messages
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY}
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - DATABASE_URL=postgresql://airflow:airflow@postgres:5432/messages
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - PYTHONPATH=/opt/airflow/src
      - MONGODB_URI=mongodb://admin:admin123@mongodb:27017/messages_db?authSource=admin
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - AIRFLOW_VAR_MONGODB_URI=mongodb://admin:admin123@mongodb:27017/messages_db?authSource=admin
      - WORKSPACE_PATH=/opt/airflow/src
      - FILTER_LINKS=${FILTER_LINKS:-true}
      - REQUIRED_DIGITS=${REQUIRED_DIGITS:-19}
      - EXCLUDE_TERMS=${EXCLUDE_TERMS:-}
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
      - /opt/airflow/src/node_modules
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./data:/data
      - ./.env:/opt/airflow/.env
      - ./extracted-links:/opt/airflow/extracted-links
      - ./filtered-links:/opt/airflow/filtered-links
      - ./workflows:/opt/airflow/workflows
      - ./automa:/opt/automa
    command: >
      bash -c "
        echo 'Waiting for database to be ready...';
        until airflow db check; do
          echo 'Database not ready yet. Retrying in 5 seconds...';
          sleep 5;
        done;
        echo 'Database connection successful!';
        airflow scheduler
      "
    healthcheck:
      test: ["CMD-SHELL", "airflow jobs check --job-type SchedulerJob --hostname \"$${HOSTNAME}\""]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - app_network
    restart: unless-stopped

  app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: streamlit_app
    depends_on:
      postgres:
        condition: service_healthy
      mongodb:
        condition: service_healthy
    ports:
      - "8501:8501"
    volumes:
      - ./screenshots:/app/screenshots
      - ./logs:/app/logs
      - .:/app
      - ./data:/data
      - ./extracted-links:/app/extracted-links
      - ./filtered-links:/app/filtered-links
      - ./workflows:/app/workflows
    environment:
      - PYTHONPATH=/app
      - STREAMLIT_SERVER_HEADLESS=true
      - DATABASE_URL=postgresql://airflow:airflow@postgres:5432/messages
      - MONGODB_URI=mongodb://admin:admin123@mongodb:27017/messages_db?authSource=admin
      - TZ=Africa/Nairobi
      - DISPLAY=:99
      - WORKSPACE_PATH=/app/src
      - FILTER_LINKS=${FILTER_LINKS:-true}
      - REQUIRED_DIGITS=${REQUIRED_DIGITS:-19}
      - EXCLUDE_TERMS=${EXCLUDE_TERMS:-}
    cap_add:
      - SYS_ADMIN
    command: >
      bash -c "
        Xvfb :99 -screen 0 1920x1080x24 -ac +extension GLX +render -noreset &
        export DISPLAY=:99
        streamlit run main.py --server.address=0.0.0.0 --server.port=8501 --server.fileWatcherType=auto
      "
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8501/_stcore/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - app_network
    restart: unless-stopped

  db-backup:
    image: alpine:latest
    container_name: db_backup
    depends_on:
      postgres:
        condition: service_healthy
      mongodb:
        condition: service_healthy
    volumes:
      - ./backups:/backups
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=messages
      - BACKUP_SCHEDULE=${BACKUP_SCHEDULE:-0 2 * * *}
      - PGPASSWORD=airflow
      - MONGODB_URI=mongodb://admin:admin123@mongodb:27017/messages_db?authSource=admin
    command: >
      sh -c "
        apk add --no-cache postgresql-client dcron mongodb-tools &&
        mkdir -p /backups &&
        echo '$$(echo \"$${BACKUP_SCHEDULE:-0 2 * * *}\") /bin/sh -c \"\
          timestamp=$$(date +%Y%m%d_%H%M%S); \
          pg_dump -U $$POSTGRES_USER -h $$POSTGRES_HOST -p $$POSTGRES_PORT $$POSTGRES_DB > /backups/messages_$$timestamp.sql; \
          mongodump --uri=$$MONGODB_URI --out=/backups/mongodb_$$timestamp; \
          find /backups -name \"*.sql\" -mtime +7 -delete; \
          find /backups -name \"mongodb_*\" -type d -mtime +7 -exec rm -rf {} +; \
          echo \"Backup completed at $$timestamp\"\"' > /etc/crontabs/root &&
        crond -f
      "
    networks:
      - app_network
    restart: unless-stopped
    profiles:
      - backup

volumes:
  postgres_data:
    driver: local
  mongodb_data:
    driver: local
  data:
    driver: local

networks:
  app_network:
    driver: bridge
    driver_opts:
      com.docker.network.bridge.name: app_bridge
